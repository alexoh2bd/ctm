{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7b7da5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:26.904515Z",
     "iopub.status.busy": "2025-06-02T03:56:26.904271Z",
     "iopub.status.idle": "2025-06-02T03:56:33.675873Z",
     "shell.execute_reply": "2025-06-02T03:56:33.675297Z"
    },
    "papermill": {
     "duration": 6.777851,
     "end_time": "2025-06-02T03:56:33.677336",
     "exception": false,
     "start_time": "2025-06-02T03:56:26.899485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input/imagenet100'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4c6245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:33.686460Z",
     "iopub.status.busy": "2025-06-02T03:56:33.685833Z",
     "iopub.status.idle": "2025-06-02T03:56:33.693370Z",
     "shell.execute_reply": "2025-06-02T03:56:33.692642Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013087,
     "end_time": "2025-06-02T03:56:33.694537",
     "exception": false,
     "start_time": "2025-06-02T03:56:33.681450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_all_data(data_dir, json_mapping_path):\n",
    "    \"\"\"\n",
    "    Collect all image paths and labels in a deterministic way\n",
    "    \"\"\"\n",
    "    data_dir = (data_dir)\n",
    "    \n",
    "    # Load class mapping\n",
    "    with open(json_mapping_path, 'r') as f:\n",
    "        folder_to_class = json.load(f)\n",
    "    \n",
    "    # Create class to index mapping\n",
    "    classes = sorted(list(set(folder_to_class.values())))\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    \n",
    "    # Collect all image paths and labels\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "    directories = os.listdir(data_dir)[1:]\n",
    "\n",
    "    # Sort folder names for deterministic ordering\n",
    "    folder_names = []\n",
    "    folder_paths = []\n",
    "\n",
    "    for d in directories:\n",
    "        folder_names.extend([f for f in os.listdir(f'{data_dir}/{d}')\n",
    "                              if f in folder_to_class])\n",
    "        folder_paths.extend([os.path.join(f'{data_dir}/{d}', f) for f in os.listdir(f'{data_dir}/{d}')\n",
    "                              if f in folder_to_class])\n",
    "    # print(folder_names[0])\n",
    "    # print(folder_paths[0])\n",
    "    for i, folder_name in enumerate(folder_names):\n",
    "        if os.path.isdir(folder_paths[i]):\n",
    "            class_name = folder_to_class[folder_name]\n",
    "            class_idx = class_to_idx[class_name]\n",
    "            \n",
    "            # Get all image files and sort them for deterministic ordering\n",
    "            image_files = sorted([\n",
    "                os.path.join(folder_paths[i], img_file) for img_file in os.listdir(folder_paths[i])\n",
    "                if img_file.endswith('.JPEG')\n",
    "            ])\n",
    "            # print(image_files)\n",
    "            # for img_file in image_files:\n",
    "            all_image_paths.extend(image_files)\n",
    "            all_labels.extend([class_idx]*len(image_files))\n",
    "    \n",
    "    return all_image_paths, all_labels, classes, class_to_idx, folder_to_class\n",
    "# collect_all_data(root, f'{root}/Labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7e90d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:33.701398Z",
     "iopub.status.busy": "2025-06-02T03:56:33.700958Z",
     "iopub.status.idle": "2025-06-02T03:56:33.706842Z",
     "shell.execute_reply": "2025-06-02T03:56:33.706069Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010263,
     "end_time": "2025-06-02T03:56:33.707846",
     "exception": false,
     "start_time": "2025-06-02T03:56:33.697583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split data paths and labels\n",
    "def split(all_image_paths, all_labels, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data once to ensure mutual exclusivity\n",
    "    \"\"\"\n",
    "    # print(f\"Splitting: {all_image_paths[0]}\")\n",
    "    # First split: separate test set\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        all_image_paths, all_labels,\n",
    "        test_size=test_size,\n",
    "        stratify=all_labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: separate train and validation from remaining data\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=val_size_adjusted,\n",
    "        stratify=y_temp,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    # print(X_train[0])\n",
    "    # Verify mutual exclusivity\n",
    "    train_set = set(X_train)\n",
    "    val_set = set(X_val)\n",
    "    test_set = set(X_test)\n",
    "    # print(train_set[0])\n",
    "    \n",
    "    assert len(train_set.intersection(val_set)) == 0, \"Train and validation sets overlap!\"\n",
    "    assert len(train_set.intersection(test_set)) == 0, \"Train and test sets overlap!\"\n",
    "    assert len(val_set.intersection(test_set)) == 0, \"Validation and test sets overlap!\"\n",
    "    \n",
    "    print(\"✓ Data splits verified as mutually exclusive\")\n",
    "    print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "    \n",
    "    return {\n",
    "        'train': {'paths': X_train, 'labels': y_train},\n",
    "        'val': {'paths': X_val, 'labels': y_val},\n",
    "        'test': {'paths': X_test, 'labels': y_test}\n",
    "    }\n",
    "# img_path_splits = split(img_paths, labels)\n",
    "# img_path_splits['train']['paths'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbc25cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:33.714017Z",
     "iopub.status.busy": "2025-06-02T03:56:33.713812Z",
     "iopub.status.idle": "2025-06-02T03:56:33.718431Z",
     "shell.execute_reply": "2025-06-02T03:56:33.717902Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.008928,
     "end_time": "2025-06-02T03:56:33.719436",
     "exception": false,
     "start_time": "2025-06-02T03:56:33.710508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class imagenet100(Dataset):\n",
    "    def __init__(self, image_paths, labels, classes, classes_to_idx, transform = None, split=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.classes = classes\n",
    "        self.classes_to_idx = classes_to_idx\n",
    "        self.num_classes = len(classes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d22c4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:33.725522Z",
     "iopub.status.busy": "2025-06-02T03:56:33.725315Z",
     "iopub.status.idle": "2025-06-02T03:56:38.699780Z",
     "shell.execute_reply": "2025-06-02T03:56:38.698947Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 4.979114,
     "end_time": "2025-06-02T03:56:38.701309",
     "exception": false,
     "start_time": "2025-06-02T03:56:33.722195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def get_transforms(input_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),     # Match ResNet18 input\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d00f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:38.708769Z",
     "iopub.status.busy": "2025-06-02T03:56:38.708456Z",
     "iopub.status.idle": "2025-06-02T03:56:38.714686Z",
     "shell.execute_reply": "2025-06-02T03:56:38.714129Z"
    },
    "papermill": {
     "duration": 0.011269,
     "end_time": "2025-06-02T03:56:38.715716",
     "exception": false,
     "start_time": "2025-06-02T03:56:38.704447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "def create_data_loaders(data_dir, json_mapping, batch_size=8, num_workers=4, input_size=224):\n",
    "    img_paths, labels, classes, class_to_idx, folder_to_class = collect_all_data(data_dir, json_mapping)\n",
    "    # print(img_paths[0]) \n",
    "    splits = split(img_paths, labels)\n",
    "    transform = get_transforms(input_size)\n",
    "    print(splits['train']['paths'][0])\n",
    "    # Create datasets\n",
    "    train_dataset = imagenet100(\n",
    "        splits['train']['paths'], \n",
    "        splits['train']['labels'], \n",
    "        classes,\n",
    "        class_to_idx,\n",
    "        transform=transform, \n",
    "    )\n",
    "    \n",
    "    val_dataset = imagenet100(\n",
    "        splits['val']['paths'], \n",
    "        splits['val']['labels'], \n",
    "        classes,\n",
    "        class_to_idx,\n",
    "        transform=transform, \n",
    "    )\n",
    "    \n",
    "    test_dataset = imagenet100(\n",
    "        splits['test']['paths'], \n",
    "        splits['test']['labels'], \n",
    "        classes,\n",
    "        class_to_idx,\n",
    "        transform=transform, \n",
    "    )\n",
    "    # print(train_dataset.image_paths)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True  # Faster GPU transfer\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f\"Dataset sizes:\")\n",
    "    print(f\"Train: {len(train_dataset)} images\")\n",
    "    print(f\"Validation: {len(val_dataset)} images\")\n",
    "    print(f\"Test: {len(test_dataset)} images\")\n",
    "    print(f\"Number of classes: {len(classes)}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578d4227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:38.721772Z",
     "iopub.status.busy": "2025-06-02T03:56:38.721541Z",
     "iopub.status.idle": "2025-06-02T03:56:43.317821Z",
     "shell.execute_reply": "2025-06-02T03:56:43.316877Z"
    },
    "papermill": {
     "duration": 4.600637,
     "end_time": "2025-06-02T03:56:43.319061",
     "exception": false,
     "start_time": "2025-06-02T03:56:38.718424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data splits verified as mutually exclusive\n",
      "Train: 94500, Val: 13500, Test: 27000\n",
      "/kaggle/input/imagenet100/train.X4/n01860187/n01860187_1819.JPEG\n",
      "Dataset sizes:\n",
      "Train: 94500 images\n",
      "Validation: 13500 images\n",
      "Test: 27000 images\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "root = f\"/kaggle/input/imagenet100\"\n",
    "train_loader, val_loader, test_loader, num_classes = create_data_loaders(root, os.path.join(root, 'Labels.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8422b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:43.325982Z",
     "iopub.status.busy": "2025-06-02T03:56:43.325734Z",
     "iopub.status.idle": "2025-06-02T03:56:44.075191Z",
     "shell.execute_reply": "2025-06-02T03:56:44.074068Z"
    },
    "papermill": {
     "duration": 0.754241,
     "end_time": "2025-06-02T03:56:44.076420",
     "exception": false,
     "start_time": "2025-06-02T03:56:43.322179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoaders...\n",
      "Batch 0: Images shape: torch.Size([8, 3, 224, 224]), Labels shape: torch.Size([8])\n",
      "Label range: 14 to 73\n",
      "Batch 1: Images shape: torch.Size([8, 3, 224, 224]), Labels shape: torch.Size([8])\n",
      "Label range: 11 to 92\n",
      "Batch 2: Images shape: torch.Size([8, 3, 224, 224]), Labels shape: torch.Size([8])\n",
      "Label range: 15 to 90\n",
      "\n",
      "First 10 classes: ['American alligator, Alligator mississipiensis', 'American coot, marsh hen, mud hen, water hen, Fulica americana', 'Dungeness crab, Cancer magister', 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis', 'agama', 'albatross, mollymawk', 'axolotl, mud puppy, Ambystoma mexicanum', 'bald eagle, American eagle, Haliaeetus leucocephalus', 'banded gecko', 'barn spider, Araneus cavaticus']\n",
      "Class to index mapping (first 5): {'American alligator, Alligator mississipiensis': 0, 'American coot, marsh hen, mud hen, water hen, Fulica americana': 1, 'Dungeness crab, Cancer magister': 2, 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis': 3, 'agama': 4}\n",
      "\n",
      " first 10 image paths: ['/kaggle/input/imagenet100/train.X4/n01860187/n01860187_1819.JPEG', '/kaggle/input/imagenet100/train.X4/n01806143/n01806143_55893.JPEG', '/kaggle/input/imagenet100/train.X1/n01820546/n01820546_5742.JPEG', '/kaggle/input/imagenet100/train.X2/n01843383/n01843383_5766.JPEG', '/kaggle/input/imagenet100/train.X3/n01664065/n01664065_15929.JPEG', '/kaggle/input/imagenet100/train.X3/n01828970/n01828970_10882.JPEG', '/kaggle/input/imagenet100/val.X/n01824575/ILSVRC2012_val_00015739.JPEG', '/kaggle/input/imagenet100/train.X1/n01818515/n01818515_4408.JPEG', '/kaggle/input/imagenet100/train.X2/n02077923/n02077923_10374.JPEG', '/kaggle/input/imagenet100/train.X2/n01740131/n01740131_5731.JPEG']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting DataLoaders...\")\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}: Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "    print(f\"Label range: {labels.min().item()} to {labels.max().item()}\")\n",
    "    if batch_idx == 2:  # Just show first few batches\n",
    "        break\n",
    "\n",
    "\n",
    "# Show some class information\n",
    "print(f\"\\nFirst 10 classes: {train_loader.dataset.classes[:10]}\")\n",
    "print(f\"Class to index mapping (first 5): {dict(list(train_loader.dataset.classes_to_idx.items())[:5])}\")\n",
    "print(f\"\\n first 10 image paths: {train_loader.dataset.image_paths[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad19e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:44.083989Z",
     "iopub.status.busy": "2025-06-02T03:56:44.083739Z",
     "iopub.status.idle": "2025-06-02T03:56:44.094685Z",
     "shell.execute_reply": "2025-06-02T03:56:44.093931Z"
    },
    "papermill": {
     "duration": 0.016102,
     "end_time": "2025-06-02T03:56:44.095808",
     "exception": false,
     "start_time": "2025-06-02T03:56:44.079706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride, dilation=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels, \n",
    "        out_channels=out_channels, \n",
    "        kernel_size=3, \n",
    "        stride=stride, \n",
    "        dilation=dilation, \n",
    "        padding=dilation, \n",
    "        bias=False,\n",
    "    )\n",
    "    \n",
    "class block(nn.Module):\n",
    "    '''\n",
    "    Basic Block: 3x3 Conv -> Batch Norm 1 -> ReLU -> 3x3 Conv -> Batch Norm 2 -> += initial -> ReLU\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # add another layer if channel\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.ReLU(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # skip connection / identity matching\n",
    "        out += self.shortcut(x)\n",
    "        out = self.ReLU(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class resnet18(nn.Module):\n",
    "    def __init__(self, stride=1):\n",
    "        super(resnet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = conv3x3(3, self.in_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.layer1 = self.make_layer(64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=1)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=1)\n",
    "        self.layer4 = self.make_layer(512, 2, stride=1)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "        \n",
    "    def make_layer(self, out_channels, num_blocks, stride=1):\n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride=stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f43add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:44.102938Z",
     "iopub.status.busy": "2025-06-02T03:56:44.102507Z",
     "iopub.status.idle": "2025-06-02T03:56:44.213611Z",
     "shell.execute_reply": "2025-06-02T03:56:44.212728Z"
    },
    "papermill": {
     "duration": 0.115999,
     "end_time": "2025-06-02T03:56:44.214795",
     "exception": false,
     "start_time": "2025-06-02T03:56:44.098796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11,220,132\n",
      "Trainable parameters: 11,220,132\n",
      "Model size: 42.80 MB\n",
      "Model size: 0.042 GB\n"
     ]
    }
   ],
   "source": [
    "def get_model_size(model):\n",
    "    # Count total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # Calculate memory usage (assumes float32 = 4 bytes)\n",
    "    total_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Model size: {total_size / 1024**2:.2f} MB\")\n",
    "    print(f\"Model size: {total_size / 1024**3:.3f} GB\")\n",
    "    \n",
    "    return total_params, total_size\n",
    "\n",
    "# Usage\n",
    "total_params, model_size = get_model_size(resnet18())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0709a07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T03:56:44.222680Z",
     "iopub.status.busy": "2025-06-02T03:56:44.222422Z",
     "iopub.status.idle": "2025-06-02T03:56:44.262537Z",
     "shell.execute_reply": "2025-06-02T03:56:44.261362Z"
    },
    "papermill": {
     "duration": 0.045311,
     "end_time": "2025-06-02T03:56:44.263684",
     "exception": true,
     "start_time": "2025-06-02T03:56:44.218373",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0 MB\n",
      "Reserved: 0 MB\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'model' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2436752901.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclean_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_19/2436752901.py\u001b[0m in \u001b[0;36mclean_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Check current usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m  \u001b[0;31m# Replace with your variable names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'model' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import gc \n",
    "# Check current usage\"\n",
    "def print_memory():\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated()/1024**2:.0f} MB\")\n",
    "    print(f\"Reserved: {torch.cuda.memory_reserved()/1024**2:.0f} MB\")\n",
    "    # Get detailed memory info\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "def clean_memory():\n",
    "    # Check current usage\n",
    "    del model, optimizer, criterion  # Replace with your variable names\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "print_memory()\n",
    "clean_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01cbe70",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-02T02:11:27.911564Z",
     "iopub.status.busy": "2025-06-02T02:11:27.910880Z",
     "iopub.status.idle": "2025-06-02T02:11:29.619057Z",
     "shell.execute_reply": "2025-06-02T02:11:29.617860Z",
     "shell.execute_reply.started": "2025-06-02T02:11:27.911541Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in (range(10)):\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(ouputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "        del outputs, loss\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Epoch {epoch} loss: {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a3d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T02:46:06.379850Z",
     "iopub.status.busy": "2025-06-02T02:46:06.379303Z",
     "iopub.status.idle": "2025-06-02T02:46:06.388037Z",
     "shell.execute_reply": "2025-06-02T02:46:06.387299Z",
     "shell.execute_reply.started": "2025-06-02T02:46:06.379829Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def memory_optimized_training():\n",
    "    # Model setup\n",
    "    model = resnet18()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Enable gradient checkpointing if available (saves memory during backprop)\n",
    "    if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "        model.gradient_checkpointing_enable()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Mixed precision training setup (uses FP16, saves ~50% memory)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Monitor memory usage\n",
    "    def print_memory_usage(stage=\"\"):\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "            reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "            print(f\"{stage} - Allocated: {allocated:.1f}MB, Reserved: {reserved:.1f}MB\")\n",
    "    \n",
    "    print_memory_usage(\"Initial\")\n",
    "    \n",
    "    # Training loop with memory optimizations\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # Move data to GPU\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)  # Fixed typo: ouputs -> outputs\n",
    "            \n",
    "            # Mixed precision backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Explicit cleanup (helps with memory fragmentation)\n",
    "            del outputs, loss, images, labels\n",
    "            \n",
    "            # Optional: Clear cache every N iterations to prevent fragmentation\n",
    "            if i % 50 == 0:  # Adjust frequency as needed\n",
    "                torch.cuda.empty_cache()\n",
    "                if i % 100 == 0:  # Less frequent memory reporting\n",
    "                    print_memory_usage(f\"Epoch {epoch+1}, Batch {i}\")\n",
    "        \n",
    "        # End of epoch cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  # Python garbage collection\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}/10 - Loss: {avg_loss:.4f}')\n",
    "        print_memory_usage(f\"End Epoch {epoch+1}\")\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    print_memory_usage(\"Final\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c757d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T02:56:07.377152Z",
     "iopub.status.busy": "2025-06-02T02:56:07.376413Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = memory_optimized_training()\n",
    "\n",
    "torch.save(model.state_dict(), \"resnet18_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1488d4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2534324,
     "datasetId": 1500837,
     "sourceId": 2491748,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.243594,
   "end_time": "2025-06-02T03:56:46.996694",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-02T03:56:22.753100",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
